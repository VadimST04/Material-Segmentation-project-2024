{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPo7U1/sLxxBBRGPyer8Z/U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJ_EZPvjtd0m","executionInfo":{"status":"ok","timestamp":1717452471394,"user_tz":-120,"elapsed":21794,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"}},"outputId":"fc590138-cd6f-4569-d9ed-77ed758be72f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/proj_image_segmentation_valid/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XCW1z-sthe0","executionInfo":{"status":"ok","timestamp":1717452471395,"user_tz":-120,"elapsed":17,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"}},"outputId":"433e6aa9-149e-4305-c076-e8b1410f450d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/proj_image_segmentation_valid\n"]}]},{"cell_type":"code","source":["!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch albumentations"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ez2L61mytiq_","executionInfo":{"status":"ok","timestamp":1717452577585,"user_tz":-120,"elapsed":106200,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"}},"outputId":"ecb3a180-a884-47e2-e182-179716ec076c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/qubvel/segmentation_models.pytorch\n","  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-c3mqphsm\n","  Running command git clone --filter=blob:none --quiet https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-c3mqphsm\n","  Resolved https://github.com/qubvel/segmentation_models.pytorch to commit 3d6da1d74636873372c265f300862a6a6d01777d\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Collecting albumentations\n","  Downloading albumentations-1.4.8-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (0.18.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.7 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (4.66.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (9.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (1.16.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.3.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (0.23.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (0.4.3)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n","Collecting scikit-image>=0.21.0 (from albumentations)\n","  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.0)\n","Collecting scikit-learn>=1.3.2 (from albumentations)\n","  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.7.2)\n","Collecting albucore>=0.0.4 (from albumentations)\n","  Downloading albucore-0.0.7-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.4->albumentations) (2.0.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.18.3)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n","Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n","  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.5.22)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (1.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (1.3.0)\n","Building wheels for collected packages: segmentation_models_pytorch, efficientnet-pytorch, pretrainedmodels\n","  Building wheel for segmentation_models_pytorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segmentation_models_pytorch: filename=segmentation_models_pytorch-0.3.4.dev0-py3-none-any.whl size=109567 sha256=bc6b23c4797f7c6eb1799a02e097db7bcf8cc97ca61e71e269ab92f3065fdef6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-66uaenqw/wheels/1a/49/5f/858bc2741660e381e83f1d8b297edc4d9f0561f29becaee577\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=5f634464a50fd043746aa4fee40519b942719185bed0118244ca641304be6325\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=811f5b8e493e95eee4cfad15ae13021f1a034dd5be03d9aa8290d92c067f4dff\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built segmentation_models_pytorch efficientnet-pytorch pretrainedmodels\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, imageio, scikit-learn, scikit-image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, albucore, nvidia-cusolver-cu12, albumentations, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.31.6\n","    Uninstalling imageio-2.31.6:\n","      Successfully uninstalled imageio-2.31.6\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.3.1\n","    Uninstalling albumentations-1.3.1:\n","      Successfully uninstalled albumentations-1.3.1\n","Successfully installed albucore-0.0.7 albumentations-1.4.8 efficientnet-pytorch-0.7.1 imageio-2.34.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 scikit-image-0.23.2 scikit-learn-1.5.0 segmentation_models_pytorch-0.3.4.dev0 timm-0.9.7\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import numpy as np\n","import segmentation_models_pytorch as smp\n","import torchvision\n","\n","IMAGE_HEIGHT = 256\n","IMAGE_WIDTH = 256\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TEST_IMG_DIR = \"/content/drive/MyDrive/proj_image_segmentation_valid/dataset/Data set I/Images/TEST_DATA\"\n","TEST_MASK_DIR = \"/content/drive/MyDrive/proj_image_segmentation_valid/dataset/Data set I/Masks/TEST_DATA\"\n","CHECKPOINT_PATH = \"mycheckpoint.pth.tar\"\n","SAVE_DIR = \"test_predictions/\"\n","\n","class TestDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_name = self.images[index]\n","        img_path = os.path.join(self.image_dir, img_name)\n","        mask_path = os.path.join(self.mask_dir, img_name.replace(\".tif\", \".png\"))\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","        mask[mask == 255.0] = 2.0\n","\n","        if self.transform is not None:\n","            augmentations = self.transform(image=image, mask=mask)\n","            image = augmentations[\"image\"]\n","            mask = augmentations[\"mask\"]\n","\n","        return image, mask, img_name\n","\n","def get_transforms():\n","    test_transform = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","    return test_transform\n","\n","def get_model(in_channels=3, out_channels=3):\n","    model = smp.Unet(\n","        encoder_name=\"resnet18\",\n","        encoder_weights=\"imagenet\",\n","        in_channels=in_channels,\n","        classes=out_channels,\n","    )\n","    return model\n","\n","def load_checkpoint(checkpoint_path, model, device):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_path, map_location=device)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","def dice_score(preds, targets, num_classes=3, smooth=1e-6):\n","    dice_scores = []\n","\n","    for class_index in range(num_classes):\n","        pred = (preds == class_index).float()\n","        target = (targets == class_index).float()\n","\n","        intersection = (pred * target).sum()\n","        union = pred.sum() + target.sum()\n","\n","        dice = (2. * intersection + smooth) / (union + smooth)\n","        dice_scores.append(dice.item())\n","\n","    return dice_scores\n","\n","def make_predictions(loader, model, save_dir):\n","    model.eval()\n","    os.makedirs(save_dir, exist_ok=True)\n","    loop = tqdm(loader)\n","    dice_scores = []\n","\n","    for data, masks, img_names in loop:\n","        data = data.to(device=DEVICE)\n","        masks = masks.to(device=DEVICE)\n","        with torch.no_grad():\n","            preds = torch.argmax(torch.softmax(model(data), dim=1), dim=1).float()\n","\n","        for pred, mask, img_name in zip(preds, masks, img_names):\n","            base_name = os.path.basename(img_name).replace(\".tif\", \".png\")\n","            pred_path = os.path.join(save_dir, f\"pred_{base_name}\")\n","            torchvision.utils.save_image(pred, pred_path)\n","\n","            dice = dice_score(pred, mask, num_classes=3)\n","            dice_scores.extend(dice)\n","\n","    model.train()\n","\n","    avg_dice_score = np.mean(dice_scores)\n","    print(f\"Average Dice Score: {avg_dice_score}\")\n","\n","    return avg_dice_score\n","\n","def test():\n","    test_transform = get_transforms()\n","    model = get_model(in_channels=3, out_channels=3).to(DEVICE)\n","\n","    load_checkpoint(CHECKPOINT_PATH, model, DEVICE)\n","\n","    test_ds = TestDataset(image_dir=TEST_IMG_DIR, mask_dir=TEST_MASK_DIR, transform=test_transform)\n","    test_loader = DataLoader(test_ds, batch_size=1, num_workers=0, shuffle=False)\n","\n","    make_predictions(test_loader, model, SAVE_DIR)\n","\n","if __name__ == \"__main__\":\n","    test()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CK3wvLfmtnqX","executionInfo":{"status":"ok","timestamp":1717452659574,"user_tz":-120,"elapsed":69802,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"}},"outputId":"54fff33e-5cbd-466e-d501-1d469593d7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 168MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Loading checkpoint\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:50<00:00,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["Average Dice Score: 0.8992987055579821\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}