{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20852,"status":"ok","timestamp":1717480552140,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"},"user_tz":-120},"id":"Mfwgv9wThlRj","outputId":"9a3af1d8-d5f0-4688-ce14-acd8e61913a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1717480560672,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"},"user_tz":-120},"id":"fKsBHgvPhtTY","outputId":"b13da2d7-561b-4978-da1b-263eb6786197"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/proj_image_segmentation_valid\n"]}],"source":["%cd /content/drive/MyDrive/proj_image_segmentation_valid/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":107761,"status":"ok","timestamp":1717480670987,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"},"user_tz":-120},"id":"KULy4joFh4V0","outputId":"9858b43c-fb60-48f4-9fbd-901b858317cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/qubvel/segmentation_models.pytorch\n","  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-0hw3x9zg\n","  Running command git clone --filter=blob:none --quiet https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-0hw3x9zg\n","  Resolved https://github.com/qubvel/segmentation_models.pytorch to commit 3d6da1d74636873372c265f300862a6a6d01777d\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Collecting albumentations\n","  Downloading albumentations-1.4.8-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (0.18.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.7 (from segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (4.66.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (9.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch==0.3.4.dev0) (1.16.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.3.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (0.23.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (0.4.3)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n","Collecting scikit-image>=0.21.0 (from albumentations)\n","  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.0)\n","Collecting scikit-learn>=1.3.2 (from albumentations)\n","  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.7.2)\n","Collecting albucore>=0.0.4 (from albumentations)\n","  Downloading albucore-0.0.7-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.4->albumentations) (2.0.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.18.3)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n","Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n","  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.5.22)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (1.12.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.7->segmentation_models_pytorch==0.3.4.dev0) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch==0.3.4.dev0) (1.3.0)\n","Building wheels for collected packages: segmentation_models_pytorch, efficientnet-pytorch, pretrainedmodels\n","  Building wheel for segmentation_models_pytorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segmentation_models_pytorch: filename=segmentation_models_pytorch-0.3.4.dev0-py3-none-any.whl size=109567 sha256=8d14f3ee6e710ae21ec869850f9c71fd21c8ddb5f60032ba1dd10d72214f4b19\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-sop_10_u/wheels/1a/49/5f/858bc2741660e381e83f1d8b297edc4d9f0561f29becaee577\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=aea3a26d731de8d558a0de96f8d16271537ac286af74762e2c2faa7f3a23d3ed\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=3c396b82a5b4740447dc803c87374c2184d49e9dc88f36450e70bcab1993cf63\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built segmentation_models_pytorch efficientnet-pytorch pretrainedmodels\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, imageio, scikit-learn, scikit-image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, albucore, nvidia-cusolver-cu12, albumentations, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.31.6\n","    Uninstalling imageio-2.31.6:\n","      Successfully uninstalled imageio-2.31.6\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.19.3\n","    Uninstalling scikit-image-0.19.3:\n","      Successfully uninstalled scikit-image-0.19.3\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.3.1\n","    Uninstalling albumentations-1.3.1:\n","      Successfully uninstalled albumentations-1.3.1\n","Successfully installed albucore-0.0.7 albumentations-1.4.8 efficientnet-pytorch-0.7.1 imageio-2.34.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 scikit-image-0.23.2 scikit-learn-1.5.0 segmentation_models_pytorch-0.3.4.dev0 timm-0.9.7\n"]}],"source":["!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch albumentations\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":27883,"status":"ok","timestamp":1717442456806,"user":{"displayName":"Vitaliia Maslova","userId":"07394502106353717844"},"user_tz":-120},"id":"vgcSPX0Gh9Xs","outputId":"180ca4fc-d917-4052-b184-2b73c6842e71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"]}],"source":["!pip install tqdm\n","!pip install numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zuicBVYPonh2"},"outputs":[],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import segmentation_models_pytorch as smp\n","\n","LEARNING_RATE = 1e-4\n","BATCH_SIZE = 8\n","NUM_EPOCHS = 400\n","NUM_WORKERS = 0\n","IMAGE_HEIGHT = 256\n","IMAGE_WIDTH = 256\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","PIN_MEMORY = True\n","LOAD_MODEL = False\n","SAVE_MODEL = True\n","\n","ROOT_PATH = \"/content/drive/MyDrive/proj_image_segmentation_valid/\"\n","TRAIN_IMG_DIR = os.path.join(ROOT_PATH, \"dataset/Data set I/Images/TRAIN_DATA\")\n","TRAIN_MASK_DIR = os.path.join(ROOT_PATH, \"dataset/Data set I/Masks/TRAIN_DATA\")\n","VAL_IMG_DIR = os.path.join(ROOT_PATH, \"dataset/Data set I/Images/VALIDATION_DATA\")\n","VAL_MASK_DIR = os.path.join(ROOT_PATH, \"dataset/Data set I/Masks/VALIDATION_DATA\")\n","\n","class CarbonDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_name = self.images[index]\n","        img_path = os.path.join(self.image_dir, img_name)\n","        mask_path = os.path.join(self.mask_dir, img_name.replace(\".tif\", \".png\"))\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask, img_name\n","\n","def save_checkpoint(state, filename=\"mycheckpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","def get_dataloaders(train_img_dir, train_mask_dir, val_img_dir, val_mask_dir, batch_size, transform):\n","    train_ds = CarbonDataset(image_dir=train_img_dir, mask_dir=train_mask_dir, transform=transform)\n","    val_ds = CarbonDataset(image_dir=val_img_dir, mask_dir=val_mask_dir, transform=transform)\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        num_workers=NUM_WORKERS,\n","        shuffle=True,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        num_workers=NUM_WORKERS,\n","        shuffle=False,\n","    )\n","\n","    return train_loader, val_loader\n","\n","def get_model():\n","    model = smp.Unet(\n","        encoder_name=\"resnet18\",\n","        encoder_weights=\"imagenet\",\n","        in_channels=3,\n","        classes=3\n","    )\n","    return model.to(DEVICE)\n","\n","def dice_score(preds, targets, num_classes=3, smooth=1e-6):\n","    preds = preds.contiguous()\n","    targets = targets.contiguous()\n","\n","    dice_scores = []\n","    for class_index in range(num_classes):\n","        pred = (preds == class_index).float()\n","        target = (targets == class_index).float()\n","        intersection = (pred * target).sum(dim=[1, 2])\n","        union = pred.sum(dim=[1, 2]) + target.sum(dim=[1, 2])\n","        dice = (2. * intersection + smooth) / (union + smooth)\n","        dice_scores.append(dice.mean())\n","\n","    return torch.stack(dice_scores).mean().item()\n","\n","def save_images(preds, targets, img_names, save_dir):\n","    os.makedirs(save_dir, exist_ok=True)\n","    for idx, (pred, target) in enumerate(zip(preds, targets)):\n","        torchvision.utils.save_image(\n","            pred.float() / 2 * 255,\n","            os.path.join(save_dir, f\"pred_{img_names[idx]}\")\n","        )\n","        torchvision.utils.save_image(\n","            target.float() / 2 * 255,\n","            os.path.join(save_dir, f\"mask_{img_names[idx]}\")\n","        )\n","\n","def train_fn(loader, model, optimizer, loss_fn, scaler, save_dir=\"saved_images/train\"):\n","    model.train()\n","    loop = tqdm(loader)\n","    for batch_idx, (data, targets, img_names) in enumerate(loop):\n","        data = data.to(DEVICE)\n","        targets = targets.long().to(DEVICE)\n","\n","        with torch.cuda.amp.autocast(enabled=DEVICE == \"cuda\"):\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        preds = torch.softmax(predictions, dim=1)\n","        preds = predictions.argmax(dim=1)\n","        dice = dice_score(preds, targets, num_classes=3)\n","\n","        loop.set_postfix(loss=loss.item(), dice=dice)\n","\n","        if batch_idx % 10 == 0:\n","            save_images(preds, targets, img_names, save_dir)\n","\n","def validate_fn(loader, model, loss_fn, save_dir=\"saved_images/val\"):\n","    model.eval()\n","    val_loss = 0\n","    dice_scores = []\n","    with torch.no_grad():\n","        loop = tqdm(loader)\n","        for batch_idx, (data, targets, img_names) in enumerate(loop):\n","            data = data.to(DEVICE)\n","            targets = targets.long().to(DEVICE)\n","\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","            val_loss += loss.item()\n","\n","            preds = torch.softmax(predictions, dim=1)\n","            preds = predictions.argmax(dim=1)\n","            dice = dice_score(preds, targets, num_classes=3)\n","            dice_scores.append(dice)\n","\n","            loop.set_postfix(loss=loss.item(), dice=dice)\n","\n","            if batch_idx % 10 == 0:\n","                save_images(preds, targets, img_names, save_dir)\n","\n","    return val_loss / len(loader), np.mean(dice_scores)\n","\n","def get_transforms():\n","    return A.Compose([\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","        A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n","        ToTensorV2(),\n","    ])\n","\n","def main():\n","    train_transform = get_transforms()\n","    model = get_model()\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(torch.load(\"mycheckpoint.pth.tar\"), model)\n","\n","    train_loader, val_loader = get_dataloaders(\n","        TRAIN_IMG_DIR,\n","        TRAIN_MASK_DIR,\n","        VAL_IMG_DIR,\n","        VAL_MASK_DIR,\n","        BATCH_SIZE,\n","        train_transform\n","    )\n","\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler, save_dir=\"saved_images/train\")\n","\n","        val_loss, val_dice = validate_fn(val_loader, model, loss_fn, save_dir=\"saved_images/val\")\n","        print(f\"Validation Loss: {val_loss}, Validation Dice Score: {val_dice}\")\n","\n","        if SAVE_MODEL:\n","            checkpoint = {\n","                \"state_dict\": model.state_dict(),\n","                \"optimizer\": optimizer.state_dict(),\n","            }\n","            save_checkpoint(checkpoint)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"authorship_tag":"ABX9TyNmE2b2IJ8xJ0I2YZqyUx3N"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}